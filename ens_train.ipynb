{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fee99e3a-528c-479c-a4eb-fb68ced42415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c35db8a3-2960-4e9d-aaf9-d6892a411e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_km(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = lat1.astype('float'), lon1.astype('float'), lat2.astype('float'), lon2.astype('float')\n",
    "    # 批量计算地球上两点间的球面距离\n",
    "    R = 6371e3  # 地球半径（米）\n",
    "    phi_1, phi_2 = np.radians(lat1), np.radians(lat2)\n",
    "    delta_phi = np.radians(lat2 - lat1)\n",
    "    delta_lambda = np.radians(lon2 - lon1)\n",
    "    a = np.power(np.sin(delta_phi / 2), 2) + np.cos(phi_1) * np.cos(phi_2) * np.power(np.sin(delta_lambda / 2), 2)\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c / 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1d243e2-bde5-4afb-8fbe-57c1f1192c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble_Model():\n",
    "    def __init__(self, menbers):\n",
    "        self.m = menbers\n",
    "        self.w = np.ones([1, self.m]) / self.m\n",
    "\n",
    "    def train_onetf(self, X, Y, dd=1, uu=1, vv=1, aa=1, rho=1):\n",
    "        w0 = self.w / np.sum(self.w)\n",
    "        u = np.zeros([1, self.m])\n",
    "        for k, (x, y) in enumerate(zip(X, Y)):\n",
    "            a = np.zeros([2 * self.m + 2, 2 * self.m + 2])\n",
    "            b = np.zeros([2 * self.m + 2])\n",
    "            t0, t1 = -y[0, 0], -y[0, 1] * (np.cos(np.radians(y[0, 1])) ** 2)\n",
    "            for i in range(self.m):\n",
    "                t0 += (w0[0, i] + u[0, i]) * x[i, 0]\n",
    "                t1 += (w0[0, i] + u[0, i]) * x[i, 1] * (np.cos(np.radians(y[0, 1])) ** 2)\n",
    "\n",
    "            for i in range(2 * self.m):\n",
    "                for j in range(2 * self.m):\n",
    "                    if i < self.m:\n",
    "                        a[i, j] = 2 * dd * (x[j % self.m, 0] * x[i % self.m, 0]\n",
    "                                            + x[j % self.m, 1] * (np.cos(np.radians(y[0, 1])) ** 2)\n",
    "                                            * x[i % self.m, 1] * (np.cos(np.radians(y[0, 1])) ** 2))\n",
    "                        if i == j:\n",
    "                            a[i, j] = a[i, j] + 2 * uu\n",
    "                    else:\n",
    "                        a[i, j] = 2 * dd * (x[j % self.m, 0] * x[i % self.m, 0]\n",
    "                                            + x[j % self.m, 1] * (np.cos(np.radians(y[0, 1])) ** 2)\n",
    "                                            * x[i % self.m, 1] * (np.cos(np.radians(y[0, 1])) ** 2))\n",
    "                        if i == j:\n",
    "                            a[i, j] = a[i, j] + 2 * vv\n",
    "                if i < self.m:\n",
    "                    a[i, -2] = 1 * aa\n",
    "                    b[i] = -2 * (dd * (t0 * x[i % self.m, 0] + t1 * x[i % self.m, 1] * (np.cos(np.radians(y[0, 1])) ** 2)) + u[0, i] * uu)\n",
    "                else:\n",
    "                    a[i, -1] = 1 * aa\n",
    "                    b[i] = -2 * dd * (t0 * x[i % self.m, 0] + t1 * x[i % self.m, 1] * (np.cos(np.radians(y[0, 1])) ** 2))\n",
    "            for j in range(self.m):\n",
    "                a[-2, j] = 1 * aa\n",
    "            for j in range(self.m, 2 * self.m):\n",
    "                a[-1, j] = 1 * aa\n",
    "\n",
    "            a = np.mat(a)\n",
    "            b = np.mat(b).T\n",
    "            c = np.linalg.solve(a, b)\n",
    "            c = np.array(c.T)\n",
    "            du = c[0, :self.m]\n",
    "            u = u + du\n",
    "        w0 = w0 + rho * u\n",
    "        self.w = w0 * np.sum(self.w)\n",
    "\n",
    "    def scale_onetf(self, X, Y, rho=0.1):\n",
    "        for x, y in zip(X, Y):\n",
    "            pred = self.predict(x)\n",
    "            pred_, y_ = pred[0], y[0]\n",
    "            scale = compute_scale(y_, pred_)\n",
    "            self.w = self.w * (1 - (1 - scale) * rho)\n",
    "\n",
    "    def get_w(self):\n",
    "        return self.w\n",
    "\n",
    "    def load_model(self, path):\n",
    "        a = np.load(path, allow_pickle=True)\n",
    "        self.w = a\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.matmul(self.w, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db8e5d7d-b2ab-4ada-a0d1-bbd81a4a6fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ensemble_train(epoch=1, model_path=None, num_menber=None):\n",
    "    path = './pred/processed/'\n",
    "    X = np.load(path + 'x_train.npy', allow_pickle=True) # ens成员的预测结果，shape=(n, m, 4, 2)，n个样本 * m个成员 * 4个时间步 * 经纬度\n",
    "    if type(num_menber)==int: # 选择成员数\n",
    "        X = X[:, :num_menber, :]\n",
    "    Y = np.load(path + 'y_train.npy', allow_pickle=True).reshape(-1, 1, 4, 2) # 台风路径真实值，shape=(n, 4, 2)，为了后面循环取出1*2的向量，所以添加一个维度\n",
    "    storm_num = np.load(path + 'train_tc_num.npy') # 所有台风的路径样本数按顺序排列的列表\n",
    "    print('热带气旋总数:', len(storm_num)) # 台风数量\n",
    "    time.sleep(0.01)\n",
    "    # 以下变量和循环是为了将所有路径样本按不同台风分割储存\n",
    "    start_index = 0\n",
    "    x_storm = []\n",
    "    y_storm = []\n",
    "    for i in storm_num:\n",
    "        end_index = start_index + i\n",
    "        x_storm.append(X[start_index: end_index])\n",
    "        y_storm.append(Y[start_index: end_index])\n",
    "        start_index = end_index\n",
    "\n",
    "    for time_step in range(4): # 4个时间步的集合预报模型分别训练\n",
    "        print('训练' + str(int((time_step + 1) * 6)) + 'h提前期集合预报模型：')\n",
    "        time.sleep(0.01)\n",
    "        model = Ensemble_Model(X.shape[1]) # 将ens类实例化，确定ens成员数\n",
    "        if model_path is not None: # 有训练好的模型想接着训练就按模型路径读入，实际上这个方法并不需要多次迭代和训练\n",
    "            model.load_model(path)\n",
    "        index = list(range(len(x_storm)))\n",
    "        for i in range(epoch): # 打乱台风的顺序并投入模型训练\n",
    "            start_time = datetime.datetime.now()\n",
    "            random.shuffle(index)\n",
    "            for j, k in tqdm(zip(index, list(range(len(storm_num))))):\n",
    "                x = x_storm[j]\n",
    "                y = y_storm[j]\n",
    "                # model.train_onetf(x, y, 0.83239, 151.2719, 0.2699, 0.1235, 0.79983) OMuLeT的超参数\n",
    "                model.train_onetf(x[:, :, time_step], y[:, :, time_step], 0.83239, 151.2719, 0.2699, 0.1235, 0.79983)\n",
    "                np.save('./ens_model/model_' + str(X.shape[1]) + '_' + str(int((time_step + 1) * 6)) + 'h.npy', model.w)\n",
    "            random.shuffle(index)\n",
    "            end_time = datetime.datetime.now()\n",
    "            print('epoch[' + str(i + 1) + '/' + str(epoch) + '] 耗时', (end_time - start_time).seconds, 's')\n",
    "            time.sleep(0.01) # 为了让tqdm打印的更好看，虽然并没有发挥作用...\n",
    "\n",
    "    # 以下是检验模型训练好的效果\n",
    "    APE_all = np.zeros([2, 4])\n",
    "    # 训练集\n",
    "    for time_step in range(4):\n",
    "        # 按预测时间步载入模型\n",
    "        saved_model_path = './ens_model/model_' + str(X.shape[1]) + '_' + str(int((time_step + 1) * 6)) + 'h.npy'\n",
    "        model = Ensemble_Model(X.shape[1])\n",
    "        model.load_model(saved_model_path)\n",
    "        pred = []\n",
    "        for xx, yy in zip(X[:, :, time_step], Y[:, :, time_step]):\n",
    "            p = model.predict(xx)\n",
    "            pred.append([p[0, 0], p[0, 1], yy[0, 0], yy[0, 1]])\n",
    "        pred_truth = np.array(pred)\n",
    "        APE = compute_distance_km(pred_truth[:, 0], pred_truth[:, 1], pred_truth[:, 2], pred_truth[:, 3])\n",
    "        print('APE ' + str(int((time_step + 1) * 6)) + 'h：', APE.mean(), 'SD:', np.std(APE))\n",
    "        APE_all[0, time_step] = APE.mean()\n",
    "\n",
    "    # 测试集\n",
    "    X = np.load(path + 'x_test.npy', allow_pickle=True)\n",
    "    if type(num_menber) == int:\n",
    "        X = X[:, :num_menber, :]\n",
    "    Y = np.load(path + 'y_test.npy', allow_pickle=True).reshape(-1, 1, 4, 2)\n",
    "    for time_step in range(4):\n",
    "        # 按预测时间步载入模型\n",
    "        saved_model_path = './ens_model/model_' + str(X.shape[1]) + '_' + str(int((time_step + 1) * 6)) + 'h.npy'\n",
    "        model = Ensemble_Model(X.shape[1])\n",
    "        model.load_model(saved_model_path)\n",
    "        pred = []\n",
    "        for xx, yy in zip(X[:, :, time_step], Y[:, :, time_step]):\n",
    "            p = model.predict(xx)\n",
    "            pred.append([p[0, 0], p[0, 1], yy[0, 0], yy[0, 1]])\n",
    "        pred_truth = np.array(pred)\n",
    "        APE = compute_distance_km(pred_truth[:, 0], pred_truth[:, 1], pred_truth[:, 2], pred_truth[:, 3])\n",
    "        print('APE ' + str(int((time_step + 1) * 6)) + 'h：', APE.mean(), 'SD:', np.std(APE))\n",
    "        APE_all[1, time_step] = APE.mean()\n",
    "    return APE_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fc1f0d6-e9db-4d53-bd71-1041335a35dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ensemble_test(model_path='./ens_model/', data_path='./pred/processed/', num_menber=None, is_save=False):\n",
    "    APE_all = np.zeros([1, 4])\n",
    "    # 测试集\n",
    "    X = np.load(data_path + 'x_test.npy', allow_pickle=True)\n",
    "    if type(num_menber) == int:\n",
    "        X = X[:, :num_menber, :]\n",
    "    Y = np.load(data_path + 'y_test.npy', allow_pickle=True).reshape(-1, 1, 4, 2)\n",
    "    all_pred_truth = []\n",
    "    for time_step in range(4):\n",
    "        # 按预测时间步载入模型\n",
    "        saved_model_path = model_path + 'model_' + str(X.shape[1]) + '_' + str(int((time_step + 1) * 6)) + 'h.npy'\n",
    "        model = Ensemble_Model(X.shape[1])\n",
    "        model.load_model(saved_model_path)\n",
    "        pred = []\n",
    "        for xx, yy in zip(X[:, :, time_step], Y[:, :, time_step]):\n",
    "            p = model.predict(xx)\n",
    "            pred.append([p[0, 0], p[0, 1], yy[0, 0], yy[0, 1]])\n",
    "        pred_truth = np.array(pred)\n",
    "        all_pred_truth.append(np.expand_dims(pred_truth, axis=1))\n",
    "        APE = compute_distance_km(pred_truth[:, 0], pred_truth[:, 1], pred_truth[:, 2], pred_truth[:, 3])\n",
    "        print('APE ' + str(int((time_step + 1) * 6)) + 'h：', APE.mean(), 'SD:', np.std(APE))\n",
    "        APE_all[0, time_step] = APE.mean()\n",
    "    all_pred_truth = np.array(all_pred_truth)\n",
    "    if is_save:\n",
    "        np.save('./pred/ens_test/model_' + str(X.shape[1]) + '_test_pred.npy', all_pred_truth)\n",
    "    return APE_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a73fae-93f0-47b2-a56d-021f1ad2265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_menber = 5\n",
    "Ensemble_train(1, num_menber=num_menber)\n",
    "Ensemble_test(num_menber=num_menber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33183349-2434-4714-be31-afc723f18f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_menber = 5\n",
    "Ensemble_train(1, num_menber=num_menber)\n",
    "Ensemble_test(num_menber=num_menber)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
